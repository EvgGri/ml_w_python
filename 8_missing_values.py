import pandas as pd
from io import StringIO

csv_data = '''A,B,C,D
            1.0, 2.0, 3.0, 4.0
            5.0, 6.0,, 8.0
            10.0,11.0,12.0,'''

# StringIO позволяет считывать строковое значение, присвоенное переменной csv_data, в объект DataFrame библиотеки pandas так, как будто
# это обычный csv файл
df = pd.read_csv (StringIO (csv_data))
df

# Сколько пустых значений в столбцах
df.isnull().sum()

# Scikit-learn предназначена для работы с массивами NumPy, но можно предварительно обрабатывать в Pandas DataFrame.
# Чтобы получить доступ к базовому массиву NumPy таблицы DataFrame, необходимо использовать атрибут values
df.values

# Удаление столбцов или строк с пропущенными значениями
df.dropna()

# Убираем столбцы в которых есть как минимум 1 пропущенное значение
df.dropna(axis=1)

# Отбросить строки, если только все столбцы содержат NaN
df.dropna(how='all')

# Отбросить строки, если в них менее 4 значений не-NaN (релевантных значений менее 4)
df.dropna(thresh=4)

# Отбросить строки, если в определенных столбцах есть NaN
df.dropna(subset=['C'])

# Интерполяция значений
# Замена средним значением
# Если поменять axis = 0  на axis = 1, то будет вычислено среднее строки
# Другими значениями параметра strategy может быть median или most_frequent
from sklearn.preprocessing import Imputer
imr = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)
imr = imr.fit(df)
imputed_data = imr.transform(df.values)
imputed_data

# Imputer - это класс-преобразователь. Для него существует 2 метода, которые используются:
# для извлечения метод fit, для преобразования используется метод transform

# Обработка категориальных данных
# Существует 2 типа категориальных данных: порядковые и номинальные (можно сравнивать и нельзя)

df = pd.DataFrame([
                  ['зеленый', 'М', 10.1, 'класс1'],
                  ['красный', 'L', 13.5, 'класс2'],
                  ['синий', 'XL', 15.3, 'класс1']
                  ])
df.columns = ['цвет','размер','цена','метка']
df

# Преобразование порядковых признаков
# Чтобы убедиться, что алгоритмы нтерпретируют порядковые признаки правильно, мы должны перевести категориальные строковые значения в целочисленные
size_mapping = { #словарь соответствий
                'XL': 3,
                'L': 2,
                'М': 1
                }

df['размер'] = df['размер'].map(size_mapping)
df

# Если на другом шаге необходимо перевести целочисленные значения назад в исходные, можно задать словарь обратного соответсвия
size_mapping.items()
inv_size_mapping = {v: k for k, v in size_mapping.items()}
inv_size_mapping

# df['размер'] = df['размер'].map(inv_size_mapping)

# Кодирование меток классов
# В Python во многих библиотеках машинного обучения есть требование, чтобы метки классов кодировались, как целочисленные значения
# Нужно помнить, что метки классов не являются порядковыми, поэтому не имеет значения, какое число мы присвоим текстовой метке
import numpy as np
class_mapping = {label:idx for idx,label in
                 enumerate(np.unique(df['метка']))}
class_mapping

# Затем можно применить словарь соответствий для преобразования меток классов в целые числа
df['метка'] = df['метка'].map(class_mapping)
df

# Чтобы вернуть числовые метки классов назад в строковые, можно сделать следующее:
inv_class_mapping = {v: k for k, v in class_mapping.items()}
df['метка'] = df['метка'].map(inv_class_mapping)
df

# В библиотеке Scikit-Learn реализован вспомогательный класс LabelEncoder, который выполняет то же самое:
from sklearn.preprocessing import LabelEncoder
class_le = LabelEncoder()
y = class_le.fit_transform(df['метка'].values)
y
# fit_transform - это сокращенная альтернатива раздельному вызову методов fit и transform
# Причем, этот метод можно использовать для преобразовния целочисленных меток классов назад в их первоначальное строковое преобразование
class_le.inverse_transform(y)

# Прямое кодирование на номинальных данных - метод, позволяющий избежать следующей ошибки:
# Это не правильно, т.к. после обучения алгоритм будет понимать, что зеленый больше синего, красный больше зеленого.
X = df[['цвет', 'размер', 'цена']].values
color_le = LabelEncoder()
X[:,0] = color_le.fit_transform(X[:,0])
X
# Общее обходное решение данной проблемы - применение метода прямого кодирования.
# Идея данного подхода - для номинального признака создать фиктивный признак для каждого  уникального значения.
# В данном случае можно признак цвет можно закодировать 3-мя бинарными значениями, соответствующими цветам.
# Для преобразования следует применять класс OneHotEncoderself.
from sklearn.preprocessing import OneHotEncoder
ohe=OneHotEncoder(categorical_features=[0])
ohe.fit_transform(X).toarray()
# При инициализации объекта OneHotEncoder мы при помощи параметра categorical_features задали номер столбца переменной, которую мы
# хотим преобразовать (в матрице признаков X первый столбец - это цвет).
# Когда мы используем метод transform, кодировщик OneHotEncoder по умолчанию возвращает разреженную матрицу, в целях визуализации
# мы преобразовали разреженную матрицу в регулярный плотный вид (массив numPy).
# Чтобы исключить этап с функцией toarray, можно инициализировать генератор прямого кода, указав параметр sparce=False

# Еще более удобный способ создания фиктивных признаков - это использовать метод get_dummies библиотеки pandas.
# Он выполнит преобразование только текстовых столбцов и оставит все остальные без изменений.
pd.get_dummies(df[['цена','цвет','размер']])
# OneHotEncoding - двоичный код, фиксированной длины, содержащий только одну 1. Длина кода определяется количеством кодируемых признаков.
